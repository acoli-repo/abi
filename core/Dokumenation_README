==============
Documentation 
==============

Das Projekt untegliedert sich in zwei Unterprojekt: der NLP-Pipeline und dem Webinterface für SparQL-Anfragen.
Es wurde auf Eclipse Luna entwickelt, mit der Java Version 1.8 (????)

Inhalt:
I) NLP-Pipeline
    A) Ordnerstruktur des Quellcodes
    B) Ablauf der Pipeline
    C) Externe Ressourcen
    D) Java-Bibliotheken
    E) Nutzung der Pipeline
II) Webinterface
    A) Ordnerstruktur des Quellcodes
    B) Pakete - Funktion
    C) Externe Ressourcen (blazegraph...)
III) Konfiguration
IV) Ausführen der .war-Datei




====================
I) Die NLP-Pipeline
====================



A) Ordnerstruktur des Quellcodes
================================


Pipeline -- | -- bin -- ...
            | -- lib ...
            | -- localFiles ------- | -- inputPipeline -----| -- en ------------ | filePool
            |                       |                       |                    | html
            |                       |                       |                    | pdf
            |                       |
            |                       |                       | -- de ------------ | filePool
            |                       |                                            | html
            |                       |                                            | pdf
            |                       |
            |                       | -- outputPipeline ----| -- en ------------ | xml	
            |                                                                    | txtPreprocessed
            |                                                                    | txt
            |                                                                    | sentences
            |                                                                    | mate
            |                                                                    | rdf
            |                                                                    | nquads
            |                                                | -- de ----------- | xml	
            |                                                                    | txtPreprocessed
            |                                                                    | txt
            |                                                                    | sentences
            |                                                                    | mate
            |                                                                    | rdf
            |                                                                    | nquads
            | -- src -------------- | -- helper 
                                    | -- html2txt 
                                    | -- in2rdf ----------- | -- rdfconvert-0.4 ...
                                    | -- mate ------------- | -- models ---      | english
                                                                                 | german
                                    | -- pipeline
                                    | -- properties
                                    | -- sbd -------------- | -- splitta ...
                                    | -- xml2plaintxt
                                    | -- pdf2xml


B) Ablauf der Pipeline
======================
I. Herausfiltern des Textes
1. pdf Dateien: zunächst wird anhand von pdf2xml [1] der Text der pdf-Eingabedateien in xml-Format erhalten (Pipeline/src/pdf2xml_own/pdf2xml.java). 
Dieses XML-Dokument enhält detaillierte Angaben über den herausgefilterten Text (Schriftgröße, Position, etc.). 
Aus den xml-Dateien wird anhand eines XSLT-Skripts (Pipeline/src/xml2plaintxt/xslFile.xsl) der relevante Text als plain text erhalten 
(als relevante Token wurden solche erachtet, deren Schriftgröße im Dokument am häufigsten vorkommt). 
Da pdf2xml Schwierigkeiten mit Umlauten und sonstigen Sonderzeichen hat, wird der erhaltene Text (im txtPreprocessed Ordner) noch einmal durch ein Java-Skript [2] korrigiert 
(Pipeline/src/xml2plaintxt/removeSpecialChars.java).
2. html Dateien: die Klasse Pipeline/src/html2txt/HtmlExtraction.java filtert den relevanten Text anhand von tag-Bezeichnungen aus den html-Eingabedateien heraus ("article" oder "p").

II. Sentence Boundary Detection
Anhand von splitta [3] werden die nach I. erhaltenen plain text Dateien so transformiert, dass jeder Satz in einer separaten Zeile steht (Pipeline/src/sbd/SBD.java).

III. Mate
Das Mate-Tools (/Pipeline/src/mate/mateEnglishGerman.java), welches - leicht abgeändert, um mehrere Dateien verarbeiten zu könnnen - wurde als in eine jar Datei umgewandelt und in das Projekt Pipeline importiert (liegt in lib). Mit dem Mate-Tool werden die Sätze aus II. annotiert und im mate-Format (CONLL 2009) abgespeichert.

IV. RDF Extraction
Aus den mate-Dateien werden dann die rdf-Triple extrahiert, wobei die Klasse /Pipeline/src/in2rdf/Sentence2Triple.java [4] verwendet wird. Die rdf-Triple liegen dann im Turtle Format vor. Mithilfe des RDF-Konvertierers rdfconvert-0.4 [5] (s. Funktion "turtle2nquads" in /Pipeline/src/in2rdf/Sentence2Triples.java) werden diese Turle Dateien dann in das Nquad-Format umgewandelt. 



C) Externe Ressourcen
=====================
Folgende Programme müssen installiert sein:
- Python 2.7
- Java 1.7
- xmllint (http://xmlsoft.org/xmllint.html) (unter Windows: cgwin)

Folgende externe Programme müssen ins Projekt eingefügt werden:

Programm		                |       Zielornder              |		Quelle
==============================================================================================================================================
pdf2xml                                 |  Pipeline/src/pdf2xml_own/    | https://sourceforge.net/projects/pdf2xml/
----------------------------------------------------------------------------------------------------------------------------------------------
splitta                                 |  Pipeline/src/sbd/            | https://pypi.python.org/pypi/splitta/0.1.0
----------------------------------------------------------------------------------------------------------------------------------------------
mate tool                               | als Jar (srl.jar) in lib und  | https://storage.googleapis.com/google-code-archive-source/
                                        | in Build Path                 | v2/code.google.com/mate-tools/source-archive.zip (wurde 
                                        |                               | aber abgeändert!!! Bei bedarf, bitte an uns wenden)
----------------------------------------------------------------------------------------------------------------------------------------------
mate POS, Lemma, Morph. Deutsch         | mate/models/german/(extracted)| https://storage.googleapis.com/google-code-archive-downloads/v2/
                                        |                               | code.google.com/mate-tools/ger-tagger+lemmatizer+morphology+graph-
                                        |                               | based-3.6+.tgz 					
---------------------------------------------------------------------------------------------------------------------------------------------- 
mate SRL Deutsch                        | mate/models/german/(extracted)| https://storage.googleapis.com/google-code-archive-downloads/v2/
                                        |                               | code.google.com/mate-tools/tiger-complete-predsonly
                                        |                               | -srl-4.11.srl.model
----------------------------------------------------------------------------------------------------------------------------------------------
mate POS Englisch                       | mate/models/english/          | https://storage.googleapis.com/google-code-archive-downloads/v2/
                                        |                               | code.google.com/mate-tools/CoNLL2009-ST-English-
                                        |                               | ALL.anna-3.3.postagger.model
----------------------------------------------------------------------------------------------------------------------------------------------
mate Lemma English                      | mate/models/english/          | https://storage.googleapis.com/google-code-archive-downloads/v2/
                                        |                               | code.google.com/mate-tools/CoNLL2009-ST-English-
                                        |                               | ALL.anna-3.3.lemmatizer.model
----------------------------------------------------------------------------------------------------------------------------------------------
mate Parser English                     | mate/models/english/          | https://storage.googleapis.com/google-code-archive-downloads/v2/
                                        |                               | code.google.com/mate-tools/CoNLL2009-ST-English-
                                        |                               | ALL.anna-3.3.parser.model
----------------------------------------------------------------------------------------------------------------------------------------------
mate SRL English                        | mate/models/english/          | https://storage.googleapis.com/google-code-archive-downloads/v2
                                        |                               | /code.google.com/mate-tools/CoNLL2009-ST-English-
                                        |                               | ALL.anna-3.3.srl-4.1.srl.model
----------------------------------------------------------------------------------------------------------------------------------------------
RDF Converter (ttl to nq)               | src/in2rdf/rdfconvert-0.4     | https://sourceforge.net/projects/rdfconvert/?source=typ_redirect
==============================================================================================================================================

D) Java-Bibliotheken
====================
- args4j-2.0.16.jar
- itextpdf-5.1.0.jar
- jcai-xml-0.17.2.jar
- jena-2.5.5.jar
- jsoup-1.8.3.jar
- loci_tools.jar
- org.apache.commons.io.jar
- pdfbox-1.2.0.jar


E) Nutzung der Pipeline
=======================
Zunächst müssen die Pfade in der properties Datei (example.properties unter src/properties/) angepasst werden. Nachdem die Komponenten aus C und D installiert wurden, kann die Pipeline durch Ausführen von src/pipeline/Pipeline.java als JavaApplication gestartet werden. Als Parameter für die "run"-Funktion, die die Pipeline letztendlich startet, müssen in der main-Methode noch der absolute Pfad der properties Datei (example.properties in src/properties/) und die Sprache ("en" oder "de") angepasst werden:

public static void main(String[] args) {
		String propsfile = "/home/kathrin/Dokumente/Pipeline/src/properties/example1.properties";
		String input = "de";
		run(propsfile, input);
}

Es liegt auch eine executable Jar Datei von Pipeline vor, die vom Webinterface TextAnalse benutzt wird. Sie wird wie folgt ausgeführt:

java -Xmx3g -jar pipeline.jar example.properties en

Das letzte Argument ist dabei die Sprachauswahl (en oder de).




=====================
II) Das Webinterface
=====================

A) Ordnerstruktur des Quellcodes
=================================
Technik:
       Spring MVC
	   
TextAnalyse-|                                                                
            | -- src ----
			|			| -- com.ta.bean -------------  | -- CheckFile.java
			|			|				| -- ReadwriteFiles.java
			|			|				| -- RWProperties.java
			|			|						   
			|			| -- com.ta.controller -------  | -- WebController.java
                        |
			|			| -- com.ta.converters -------  | -- parse_triples.py
			|			|				* -- rdftriples.ttl 
			|			|				* -- rdftriples.txt 
			|			|						 
			|			| -- com.ta.mode -------------  | 						  
			|			|        			| -- LoginData.java
			|			|				| -- SparQLBean.java
			|			|	
			|			| -- com.ta.remote -----------  | -- BlazegraphSesameRemote.java
			|			|     							* -- log4j.properties
			|			|
			|			| -- com.ta.resource -----------| -- Globals.java
			|			|
			|			| -- com.ta.validator ----------| -- InputValidator.java
			|			|
			|			| -- com.ta.visualisation ------| -- VisualizeQueryResult.java
			|
			| --WebContent ---
						| --resources ------------  | images
						|			    | js (haupt)
						|			    | style.css (haupt)
						|
						| -- WEB-INF -------------  | -- upload
									    | -- css (visual)
									    | -- visualize
									    | -- js_v (visual)
									    | -- jsp -- | welcome.jsp
									                | about.jsp
											| lazegraph.jsp
											| contact.jsp
										        | download.jsp
											| errorSqarQl.jsp
											| index.html
											| login.jsp
											| successSave.jsp
											| successSqarQl.jsp
											| textAnalyse.jsp
											| verwaltung.jsp
											| ViewSparql.jsp
											| visualtemp.jsp

			
B) Pakete - Funktion
=================================

- src/com/ta/bean (all javaBean classes)
   Durch CheckFile.java wärde das Ouput-Klassenpfad gecheckt.
   Die Dokumenten mittels der ReadwriteFiles Klasse können gelesen bzw geschrieben werden. RWProperties kann alle Keywords von Properties-File bearbeiten.   

- src/com/ta/controller (spring mvc)
   WebController.java ist das Kontrolle von Spring MVC Modul.
   wie die Navigationen , Aktionen, Datei in/out können dadurch passiert werden.

- src/com/ta/model (spring mvc)
   alle Modelen für die Oberfläsch.
   
- src/com/ta/remote (remote call of Blazegraph)
   Die Abfragen von Textanalyse können durch BlazegraphSesameRemote erfolgt. ps. Input sind die SparQL Abfragen.
   
- src/com/ta/resource (spring mvc)  
   alle Keywords oder relevanten Abkürzungen.
   
- src/com/ta/validator (spring mvc)  
   Die Validation von Spring MVC Modul, dadurch können die Eigaben von User prüfen. ob sie gültig sind. wenn nein, dann würde eine Error-nachricht bekommen.
   
- src/com/ta/converters
    Enthält das python Skript parse_triples.py [6]. Dieses transformiert das Ergebnis der SparQL Anfrage (das in rdftriples.ttl gespeichert 
    wird) in eine .json Datei (triples.json unter /WebContent/WEB-INF/jsp/visualize). triples.json wird wiederum durch triples.vis 
    visualisiert.


- /WebContent/WEB-INF/jsp/visualize
    Eine construct Anfrage erzeugt rdf Triples. Diese werden in eine .json Datei umgewandelt und durch triples.vis visualisiert  
    (construct.html [6]). Eine select Anfrage erzeugt eine Tabelle. Diese wird direkt nach Auführung der Anfrage (src/com/ta/remote/
    BlazegraphSesameRemote.java) unter /WebContent/WEB-INF/jsp/visualize/triples.csv gespeichert und mithilfe von d3.v3.min.js [7] 
    visualisiert (select.html). 

- /WebContent/SimpleHTTPServerWithUpload.py , upload.sh, download.sh
    Eine abgeänderte Version von [8]. Dieses python Skript dient dazu, dass der/die UserIn lokale .pdf und html. Dateien auf den Server  
    hochladen kann, um diese durch die Pipeline laufen zu lassen, die daraus Nquads Dateien erzeugt. Das Skript erhält weiterhin die Funktion, 
    die Pipeline über die Weboberfläche zu starten. Dies geschieht mithilfe von upload.sh, welche die jar. Datei der Pipeline aufruft. Die .nq 
    Dateien, die die Pipeline erzeugt, werden automatisch in /WebContent/nquads kopiert. download.sh startet einen SimpleHTTPServer (python) 
    in diesem Ordner, um die darin enthaltenen Dateien für den/die UserIn sichtbar zu machen und das Herunterladen davon zu ermöglichen. 
   
D) Java-Bibliotheken (Maven)
====================
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>
  <groupId>TextAnalyse</groupId>
  <artifactId>TextAnalyse</artifactId>
  <version>0.0.1-SNAPSHOT</version>
  <packaging>war</packaging>
  <build>
    <sourceDirectory>src</sourceDirectory>
    <plugins>
      <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-compiler-plugin</artifactId>
            <version>3.1</version>
            <configuration>
                <source>1.8</source>
                <target>1.8</target>
            </configuration>
        </plugin>
      <plugin>
        <artifactId>maven-war-plugin</artifactId>
        <version>2.3</version>
        <configuration>
          <warSourceDirectory>WebContent</warSourceDirectory>
          <failOnMissingWebXml>false</failOnMissingWebXml>
        </configuration>
      </plugin>
    </plugins>
  </build>
  <dependencies>
  <dependency>
   <groupId>org.apache.commons</groupId>
   <artifactId>commons-io</artifactId>
   <version>1.3.2</version>
  </dependency>
  	<dependency>
  		<groupId>org.springframework</groupId>
  		<artifactId>spring-webmvc</artifactId>
  		<version>4.2.5.RELEASE</version>
  	</dependency>
  	<dependency>
  		<groupId>org.springframework</groupId>
  		<artifactId>spring-web</artifactId>
  		<version>4.2.5.RELEASE</version>
  	</dependency>
  	<dependency>
  		<groupId>org.springframework</groupId>
  		<artifactId>spring-context</artifactId>
  		<version>4.2.5.RELEASE</version>
  	</dependency>
  	<dependency>
  		<groupId>org.springframework</groupId>
  		<artifactId>spring-aop</artifactId>
  		<version>4.2.5.RELEASE</version>
  	</dependency>
  	<dependency>
  		<groupId>javax.servlet</groupId>
  		<artifactId>jstl</artifactId>
  		<version>1.2</version>
  	</dependency>
  	<dependency>
  		<groupId>org.springframework</groupId>
  		<artifactId>spring-core</artifactId>
  		<version>4.2.5.RELEASE</version>
  	</dependency>
  	<dependency>
  		<groupId>org.springframework.security</groupId>
  		<artifactId>spring-security-taglibs</artifactId>
  		<version>4.0.1.RELEASE</version>
  	</dependency>
  	<dependency>
  		<groupId>commons-logging</groupId>
  		<artifactId>commons-logging</artifactId>
  		<version>1.1.3</version>
  	</dependency>
  	<dependency>
  		<groupId>opensymphony</groupId>
  		<artifactId>sitemesh</artifactId>
  		<version>2.4.2</version>
  	</dependency>
  	<dependency>
  		<groupId>javax.validation</groupId>
  		<artifactId>validation-api</artifactId>
  		<version>1.0.0.GA</version>
  	</dependency>
  	<dependency>
  		<groupId>log4j</groupId>
  		<artifactId>log4j</artifactId>
  		<version>1.2.17</version>
  	</dependency>
  	<dependency>
  		<groupId>org.hibernate</groupId>
  		<artifactId>hibernate-validator</artifactId>
  		<version>4.2.0.Final</version>
  	</dependency>
  	<dependency>
  		<groupId>com.bigdata</groupId>
  		<artifactId>bigdata</artifactId>
  		<version>1.5.2</version>
  		<exclusions>
  			<exclusion>
  				<artifactId>slf4j-log4j12</artifactId>
  				<groupId>org.slf4j</groupId>
  			</exclusion>
  			<exclusion>
  				<artifactId>commons-logging</artifactId>
  				<groupId>commons-logging</groupId>
  			</exclusion>
  			<exclusion>
  				<artifactId>javax.servlet-api</artifactId>
  				<groupId>javax.servlet</groupId>
  			</exclusion>
  		</exclusions>
  	</dependency>
  	
  	<dependency>
	<groupId>org.eclipse.jetty</groupId>
	<artifactId>jetty-client</artifactId>
	<version>9.3.8.v20160314</version>
</dependency>

  </dependencies>
  <repositories>
	<repository>
	   <id>bigdata.releases</id>
	   <url>http://www.systap.com/maven/releases</url>
 	</repository>
 	</repositories> 	
</project>



===================
III) Konfiguration
===================

- Unter WEB-INF/classes/com/ta/resource/Globals.java (in der .war Datei) muss der absolute Pfad von message.properties angepasst werden (Zeile 31: public final static String _MESSAGE_PATH) 
- Unter WEB-INF/classes/com/ta/resources/messages.properties (in der .war Datei) die absoluten Pfade anpassen
- Blazegraph .jar Datei herunterladen, falls noch nicht geschehen



=============================
IV) Ausführen der .war Datei
=============================

- blazegraph starten (java -server -Xmx4g -jar blazegraph.jar )
- .war Datei in lokalem Tomcat8 Ordner unter webapps ablegen
- Tomcat8 starten (unter /bin ausführen: sh startup.sh)
- in den Ordner TextAnalse (der beim Start von Tomcat erzeugt wird) wechseln und in PipelineJar/ResourcesPipeline/src/pdf2xml die Datei "pdftoxml.linux64.exe.1.2_7" ausführbar machen (chmod 777 pdftoxml.linux64.exe.1.2_7)
- im Browser http://localhost:8080/TextAnalyse aufrufen.

Anmerkung: User & Passwort für Verwaltung: "textanalyse", "ta1516"


Falls localhost:8081 nicht automatisch startet, dann über Konsole starten (Pfade anpassen):
$cd /home/kathrin/tomcat8/webapps/TextAnalyse/
$python SimpleHTTPServerWithUpload.py 8081 /home/kathrin/tomcat8/webapps/TextAnalyse/PipelineJar/ResourcesPipeline/localFiles/inputPipeline/ /home/kathrin/tomcat8/webapps/TextAnalyse/ /home/kathrin/tomcat8/webapps/TextAnalyse/PipelineJar/ http\://localhost\:9999/blazegraph/sparql

_____________________________

[1] https://sourceforge.net/projects/pdf2xml/
[2] Autor: Niko Schenk
[3] https://pypi.python.org/pypi/splitta/0.1.0
[4] Autor: Christian Chiarcos; abgeändert für Umlaute und Umwandlung in nquad
[5] Autor: Samuel Rönnqvist; abgeändert, sodass Turtle-Präfixe nicht beachtet werden
[6] Autor: Samuel Rönnqvist
[7] https://bl.ocks.org/ndarville/7075823 
[8] https://gist.github.com/UniIsland/3346170


